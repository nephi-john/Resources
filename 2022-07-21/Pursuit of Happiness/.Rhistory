# CHANGE PATH HERE:
mypath = "D:\\_nj_\\-github-\\Resources\\2022-07-21\\Pursuit of Happiness\\";
# YOU need to install these packages for this to work.
library(SentimentAnalysis);
library(wordcloud2);
library(wordcloud);
library(tm);
library(textclean);
library(slam);
myFile = paste0(mypath,"ORIG.txt");
ORIG = readChar(myFile, file.info(myFile)$size);
# https://www.churchofjesuschrist.org/study/scriptures/the-family-a-proclamation-to-the-world/the-family-a-proclamation-to-the-world?lang=eng
myFile = paste0(mypath,"COPY.txt");
COPY = readChar(myFile, file.info(myFile)$size);
# https://cran.r-project.org/web/packages/SentimentAnalysis/vignettes/SentimentAnalysis.html
sentiment = analyzeSentiment( c(ORIG,COPY) );
rownames(sentiment) = c("ORIG", "COPY");
sentiment;
# https://riptutorial.com/r/example/31050/create-a-term-frequency-matrix
# docs = Corpus(VectorSource( c(ORIG,COPY) ));
prepString = function(vec, stemMe=FALSE)
{
docs = Corpus(VectorSource( vec ));
docs = tm_map(docs, replace_non_ascii);
# function from textclean to remove curly quotes ” and ’
docs = tm_map(docs, replace_curly_quote);
# function from textclean to replace "it's" to "it is"
docs = tm_map(docs, replace_contraction);
docs = tm_map(docs,removeNumbers);
docs = tm_map(docs,removePunctuation);
docs = tm_map(docs,stripWhitespace);
docs = tm_map(docs, PlainTextDocument);
docs = tm_map(docs,content_transformer(tolower));
docs = tm_map(docs,removeWords, stopwords("english"));
if(stemMe)
{
docs <- tm_map(docs, stemDocument, language="english");
}
# inspect(docs);
docs;
}
doc.ORIG = prepString(c(ORIG));
doc.COPY= prepString(c(COPY));
doc.BOTH = prepString(c(ORIG,COPY));
buildFreq = function(docs)
{
dtm     = TermDocumentMatrix(docs);
words   = sort(rowSums(as.matrix(dtm)),decreasing=TRUE);
words.f = data.frame(word = names(words),freq=words);
words.f;
}
# ORIG.freq = termFreq(inspect(docs[1])$content); # ORIG
# COPY.freq = termFreq(inspect(docs[1])$content); # COPY
ORIG.freq = buildFreq(doc.ORIG);
set.seed(1234);
wordcloud2(ORIG.freq);
COPY.freq = buildFreq(doc.COPY);
set.seed(1234);
wordcloud2(COPY.freq);
doc.ORIG.s = prepString(c(ORIG), stemMe=TRUE);
doc.COPY.s= prepString(c(COPY), stemMe=TRUE);
doc.BOTH.s = prepString(c(ORIG,COPY), stemMe=TRUE);
ORIG.freq.s = buildFreq(doc.ORIG.s);
set.seed(1234);
wordcloud2(ORIG.freq.s);
COPY.freq.s = buildFreq(doc.COPY.s);
set.seed(1234);
wordcloud2(COPY.freq.s);
TABLE.both = merge(ORIG.freq.s, COPY.freq.s, by="word");
colnames(TABLE.both)=c("words","ORIG","COPY");
TABLE.both = TABLE.both[order(-TABLE.both$ORIG, -TABLE.both$COPY),];
TABLE.both;
tdm = TermDocumentMatrix(doc.BOTH);
crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))));
tdm = TermDocumentMatrix(doc.BOTH.s);
crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
names.words = TABLE.both$words;
names.docs = colnames(TABLE.both)[-1];
X = t( TABLE.both[,-1] );
rownames(X) = names.docs;
colnames(X) = names.words;
dim(X);
head(X[,1:10]);
X[,abs(X[1,] - X[2,]) > 3];
# prcomp vs princomp?
X.PCA = prcomp(t(X));  # this is only on STEM
summary(X.PCA);
str(X.PCA);
X.PCA;
biplot(X.PCA,
xlab=paste0("PC1 VAF: ",round(summary(X.PCA)$importance[2,1] * 100,1 ), "%"),
ylab=paste0("PC2 VAF: ",round(summary(X.PCA)$importance[2,2] * 100,1 ), "%"),
);
head(X[,1:10]);
a = X[1,];  # ORIG
b = X[2,];  # COPY
theta = as.numeric( (a %*% b) / (sqrt(sum(a^2)) * sqrt(sum(b^2))) );  # cosine similarity of weighted vectors (TF-IDF)
theta;
# https://www.mathworks.com/help/textanalytics/ref/bagofwords.tfidf.html
X.tf = colSums(X);  # term freq
X.idf = colSums(X != 0); # document freq
# NORM technique?
# https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Inverse_document_frequency
X.tf.s = log(1 + X.tf);
X.idf.s = log( nrow(X) / (1+X.idf) ) + 1;
X.tf.idf.s = X.tf.s * X.idf.s;  # PAIRWISE products
# https://en.wikipedia.org/wiki/Latent_semantic_analysis
## scaled X
Xs = X * X.tf.idf.s # PAIRWISE products
round(Xs[,abs(Xs[1,] - Xs[2,]) > 3],2);
round(Xs[,(Xs[1,] - Xs[2,]) < -1.5],2);
# prcomp vs princomp?
Xs.PCA = prcomp(t(Xs));  # this is only on STEM
summary(Xs.PCA);
str(Xs.PCA);
Xs.PCA;
biplot(Xs.PCA,
xlab=paste0("PC1 VAF: ",round(summary(Xs.PCA)$importance[2,1] * 100,1 ), "%"),
ylab=paste0("PC2 VAF: ",round(summary(Xs.PCA)$importance[2,2] * 100,1 ), "%"),
);
head(Xs[,1:10]);
a = Xs[1,];  # ORIG
b = Xs[2,];  # COPY
theta = as.numeric( (a %*% b) / (sqrt(sum(a^2)) * sqrt(sum(b^2))) );  # cosine similarity of weighted vectors (TF-IDF)
theta;
names.words
which(startsWith(names.words, "spir"));
which(startsWith(names.words, "slav"));
doc.BOTH
ORIG.freq.s
tail(ORIG.freq.s)
TABLE.both = merge(ORIG.freq.s, COPY.freq.s, by="word");
colnames(TABLE.both)=c("words","ORIG","COPY");
TABLE.both = TABLE.both[order(-TABLE.both$ORIG, -TABLE.both$COPY),];
TABLE.both;
?merge
TABLE.both = merge(ORIG.freq.s, COPY.freq.s, by="word", all.x=TRUE, all.y=TRUE);  # does this drop 0,1 ?
colnames(TABLE.both)=c("words","ORIG","COPY");
TABLE.both = TABLE.both[order(-TABLE.both$ORIG, -TABLE.both$COPY),];
TABLE.both;
TABLE.both = merge(ORIG.freq.s, COPY.freq.s, by="word", all.x=TRUE, all.y=TRUE);  # does this drop 0,1 ?
colnames(TABLE.both)=c("words","ORIG","COPY");
TABLE.both = TABLE.both[order(-TABLE.both$ORIG, -TABLE.both$COPY),];
TABLE.both[is.na(TABLE.both)] = 0; # NA from merge
TABLE.both;
tdm = TermDocumentMatrix(doc.BOTH);
crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))));
tdm = TermDocumentMatrix(doc.BOTH.s);
crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
names.words = TABLE.both$words;
names.docs = colnames(TABLE.both)[-1];
X = t( TABLE.both[,-1] );
rownames(X) = names.docs;
colnames(X) = names.words;
dim(X);
head(X[,1:10]);
X[,abs(X[1,] - X[2,]) > 3];
# prcomp vs princomp?
X.PCA = prcomp(t(X));  # this is only on STEM
summary(X.PCA);
str(X.PCA);
X.PCA;
biplot(X.PCA,
xlab=paste0("PC1 VAF: ",round(summary(X.PCA)$importance[2,1] * 100,1 ), "%"),
ylab=paste0("PC2 VAF: ",round(summary(X.PCA)$importance[2,2] * 100,1 ), "%"),
);
head(X[,1:10]);
a = X[1,];  # ORIG
b = X[2,];  # COPY
theta = as.numeric( (a %*% b) / (sqrt(sum(a^2)) * sqrt(sum(b^2))) );  # cosine similarity of weighted vectors (TF-IDF)
theta;
# https://www.mathworks.com/help/textanalytics/ref/bagofwords.tfidf.html
X.tf = colSums(X);  # term freq
X.idf = colSums(X != 0); # document freq
# NORM technique?
# https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Inverse_document_frequency
X.tf.s = log(1 + X.tf);
X.idf.s = log( nrow(X) / (1+X.idf) ) + 1;
X.tf.idf.s = X.tf.s * X.idf.s;  # PAIRWISE products
# https://en.wikipedia.org/wiki/Latent_semantic_analysis
## scaled X
Xs = X * X.tf.idf.s # PAIRWISE products
round(Xs[,abs(Xs[1,] - Xs[2,]) > 3],2);
round(Xs[,(Xs[1,] - Xs[2,]) < -1.5],2);
# prcomp vs princomp?
Xs.PCA = prcomp(t(Xs));  # this is only on STEM
summary(Xs.PCA);
str(Xs.PCA);
Xs.PCA;
biplot(Xs.PCA,
xlab=paste0("PC1 VAF: ",round(summary(Xs.PCA)$importance[2,1] * 100,1 ), "%"),
ylab=paste0("PC2 VAF: ",round(summary(Xs.PCA)$importance[2,2] * 100,1 ), "%"),
);
head(Xs[,1:10]);
a = Xs[1,];  # ORIG
b = Xs[2,];  # COPY
theta = as.numeric( (a %*% b) / (sqrt(sum(a^2)) * sqrt(sum(b^2))) );  # cosine similarity of weighted vectors (TF-IDF)
theta;
#which(names.words == "unalien");
#which(startsWith(names.words, "spir"));
#which(endsWith(names.words, "ip")); # relationship
# why not STEMMED
closer = c(1,2,4,8,9, 42, 61,62,34,13,36, 57,37,33,  76,55);
# from names.words
X[,closer];
round(Xs[,closer],2);
# bigrams
# Eternal Father
# heavenly parents
# universal Father and Mother -> universal Father and universal Mother
closer = c( which(names.words == "unalien"), which(names.words == "wage"), which(names.words == "trade"), which(names.words == "sex"), which(names.words == "savag"), which(names.words == "salari"), which(names.words == "settlement"), which(names.words == "ruler"), which(names.words == "represent"), which(names.words == "punish"), which(names.words == "plunder"), which(names.words == "nation"), which(names.words == "oppress"), which(names.words == "light"), which(names.words == "indian"), which(names.words == "god"), which(names.words == "evil"), which(names.words == "emigr"), which(names.words == "forbidden"), which(names.words == "frontier"), which(names.words == "disavow"), which(names.words == "contract"), which(names.words == "citizen"), which(names.words == "assum"), which(names.words == "administr"), which(names.words == "acquiesc"), which(names.words == "public"), which(names.words == "polit"), which(names.words == "british"), which(names.words == "sacr"), which(names.words == "friend"), which(names.words == "rule"), which(names.words == "system"), which(names.words == "trial"), which(names.words == "stand"), which(names.words == "pledg"), which(names.words == "rest"), which(names.words == "mercenari"), which(names.words == "life"), which(names.words == "truth"), which(names.words == "separ"), which(names.words == "judg"), which(names.words == "death"), which(names.words == "cours"), which(names.words == "creat"), which(names.words == "tyrant"), which(names.words == "object"), which(names.words == "congress"), which(names.words == "good"), which(names.words == "america"), which(names.words == "abolish"), which(names.words == "sea"), which(names.words == "king"), which(names.words == "men"), which(names.words == "live"), which(names.words == "histori"), which(names.words == "constitut"), which(names.words == "happi"), which(names.words == "common"), which(names.words == "mankind"), which(names.words == "britain"), which(names.words == "foreign"), which(names.words == "war"), which(names.words == "liberti"), which(names.words == "legislatur"), which(names.words == "justic"), which(names.words == "peac"), which(names.words == "coloni"), which(names.words == "establish"), which(names.words == "new"), which(names.words == "larg"), which(names.words == "legisl"), which(names.words == "peopl"), which(names.words == "power"), which(names.words == "state"), which(names.words == "govern"), which(names.words == "right"), which(names.words == "law"), which(names.words == "time"),  which(names.words == "declar"), which(names.words == "independ"), which(names.words == "free"), which(names.words == "will"), which(names.words == "natur"), which(names.words == "great"), which(names.words == "will"),  which(names.words == "slaveri") );
X[,closer];
round(Xs[,closer],2);
#which(names.words == "unalien");
#which(startsWith(names.words, "spir"));
#which(endsWith(names.words, "ip")); # relationship
# why not STEMMED
# closer = c(1,2,4,8,9, 42, 61,62,34,13,36, 57,37,33,  76,55);
# from names.words
closer = c(  which(names.words == "public"), which(names.words == "polit"), which(names.words == "british"), which(names.words == "sacr"), which(names.words == "friend"), which(names.words == "rule"), which(names.words == "system"), which(names.words == "trial"), which(names.words == "stand"), which(names.words == "pledg"), which(names.words == "rest"), which(names.words == "mercenari"), which(names.words == "life"), which(names.words == "truth"), which(names.words == "separ"), which(names.words == "judg"), which(names.words == "death"), which(names.words == "cours"), which(names.words == "creat"), which(names.words == "good"), which(names.words == "america"), which(names.words == "abolish"), which(names.words == "sea"), which(names.words == "king"), which(names.words == "men"), which(names.words == "live"), which(names.words == "histori"), which(names.words == "constitut"), which(names.words == "happi"), which(names.words == "common"), which(names.words == "britain"), which(names.words == "foreign"), which(names.words == "war"), which(names.words == "liberti"), which(names.words == "legislatur"), which(names.words == "coloni"), which(names.words == "establish"), which(names.words == "legisl"), which(names.words == "peopl"), which(names.words == "power"), which(names.words == "state"), which(names.words == "govern"), which(names.words == "right"), which(names.words == "law"), which(names.words == "time"),  which(names.words == "declar"), which(names.words == "independ"), which(names.words == "free"), which(names.words == "will"), which(names.words == "natur"), which(names.words == "great"), which(names.words == "will"),  which(names.words == "slaveri") );
X[,closer];
round(Xs[,closer],2);
